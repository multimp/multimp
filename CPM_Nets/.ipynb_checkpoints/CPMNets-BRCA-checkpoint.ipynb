{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util.util import read_data\n",
    "from util.get_sn import get_sn\n",
    "from util.model import CPMNets\n",
    "import util.classfiy as classfiy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import warnings\n",
    "from util.evaluation import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lsd-dim LSD_DIM] [--epochs-train N]\n",
      "                             [--epochs-test N] [--lamb LAMB]\n",
      "                             [--missing-rate MISSING_RATE] [--log-dir LOG_DIR]\n",
      "                             [--unsu UNSU]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/jieun/Library/Jupyter/runtime/kernel-df3dd4ca-daaf-430f-b803-7f0434f9755a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lsd-dim', type=int, default=512,\n",
    "                        help='dimensionality of the latent space data [default: 512]')\n",
    "parser.add_argument('--epochs-train', type=int, default=100, metavar='N',\n",
    "                        help='number of epochs to train [default: 20]')\n",
    "parser.add_argument('--epochs-test', type=int, default=100, metavar='N',\n",
    "                        help='number of epochs to test [default: 50]')\n",
    "parser.add_argument('--lamb', type=float, default=10.,\n",
    "                        help='trade off parameter [default: 10]')\n",
    "parser.add_argument('--missing-rate', type=float, default=0.1,\n",
    "                        help='view missing rate [default: 0]')\n",
    "parser.add_argument('--log-dir', default='/Users/jieun/Dropbox/Desktop/UNC/Spring2021/COMP790/FinalProject/multimp/results/', type=str,  help='saving path')\n",
    "parser.add_argument('--unsu', type=bool, default=True,\n",
    "                        help='view missing rate [default: 0]')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "    if args.unsu:\n",
    "        allData, trainData, testData, view_num = read_data('/Users/jieun/Dropbox/Desktop/UNC/Spring2021/COMP790/FinalProject/data/TCGA-BRCA_cate.pkl', Normal=1)\n",
    "        # Randomly generated missing matrix\n",
    "        Sn_all = get_sn(allData, view_num, trainData.num_examples, args.missing_rate)\n",
    "    else:\n",
    "        trainData, testData, view_num = read_data('/Users/jieun/Dropbox/Desktop/UNC/Spring2021/COMP790/FinalProject/data/TCGA-BRCA_cate.pkl',ratio=0.8, Normal=1)\n",
    "\n",
    "    # Randomly generated missing matrix\n",
    "    Sn_train = get_sn(trainData, view_num, trainData.num_examples, args.missing_rate)\n",
    "    Sn_test = get_sn(testData, view_num, testData.num_examples, args.missing_rate)\n",
    "    outdim_size = [trainData.data[str(i)].shape[1] for i in range(view_num)]\n",
    "    # set layer size\n",
    "    layer_size = [[outdim_size[i]] for i in range(view_num)]\n",
    "    layer_size_d = [[outdim_size[i], 128, 1] for i in range(view_num)]\n",
    "    # set parameter\n",
    "    epoch = [args.epochs_train, args.epochs_test]\n",
    "    learning_rate = [0.001, 0.01]\n",
    "\n",
    "\n",
    "    # train\n",
    "    if args.unsu:\n",
    "        # Model building\n",
    "        model = CPMNets(view_num,\n",
    "                        allData.cat_indicator,\n",
    "                        allData.num_examples,\n",
    "                        testData.num_examples,\n",
    "                        layer_size, layer_size_d,\n",
    "                        args.lsd_dim,\n",
    "                        learning_rate,\n",
    "                        args.lamb)\n",
    "        model.train(allData.data, Sn_all, allData.labels.reshape(allData.num_examples, 1), epoch[0])\n",
    "        #H_all = model.get_h_all()\n",
    "        # get recovered matrix\n",
    "\n",
    "        imputed_data = model.recover(allData.data, Sn_all, allData.labels.reshape(allData.num_examples, 1))\n",
    "        mean_mse, mean_auc = evaluate(allData.data, imputed_data, Sn_all, allData.MX, model.cat_indicator, view_num)\n",
    "        print('MSE is {:.4f}, MeanAUC is {:.4f}'.format(mean_mse, mean_auc))\n",
    "\n",
    "        # save results\n",
    "        root_dir = args.log_dir\n",
    "        if not os.path.exists(root_dir):\n",
    "            os.mkdir(root_dir)\n",
    "        metrics_path = os.path.join(root_dir, 'metrics')\n",
    "        mat_path = os.path.join(root_dir, 'imputed')\n",
    "        if not os.path.exists(metrics_path):\n",
    "            os.mkdir(metrics_path)\n",
    "        if not os.path.exists(mat_path):\n",
    "            os.mkdir(mat_path)\n",
    "        mat_path = mat_path + '/adni_missing_rate_' + str(args.missing_rate) + '.pkl'\n",
    "        metrics_path =  metrics_path +  '/results.csv'\n",
    "\n",
    "        ## caculate results\n",
    "        current_metrics = {}\n",
    "        current_metrics['missing_rate'] = args.missing_rate\n",
    "        current_metrics['mse'] = mean_mse\n",
    "        current_metrics['auc'] = mean_auc\n",
    "        current_metrics['epoch'] = mean_auc\n",
    "        ## save to pickle\n",
    "        with open(mat_path, 'wb') as handle:\n",
    "            pickle.dump(imputed_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        ## save to csv\n",
    "        if os.path.exists(metrics_path):\n",
    "            metrics = pd.read_csv(metrics_path, header=0)\n",
    "            metrics.append(pd.DataFrame(current_metrics, columns=['missing_rate', 'auc', 'mse'], index=[len(metrics)]))\n",
    "        else:\n",
    "            pd.DataFrame(current_metrics, index=[0], columns=['missing_rate', 'auc', 'mse', 'epochs']).to_csv(metrics_path)\n",
    "\n",
    "        # test\n",
    "        if args.unsu:\n",
    "            model.test(testData.data, Sn_test, testData.labels.reshape(testData.num_examples, 1), epoch[1])\n",
    "        H_test = model.get_h_test()\n",
    "        #label_pre = classfiy.ave(H_train, H_test, trainData.labels)\n",
    "        #print('Accuracy on the test set is {:.4f}'.format(accuracy_score(testData.labels, label_pre)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
